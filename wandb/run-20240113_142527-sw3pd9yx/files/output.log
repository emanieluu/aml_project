{'batch_size': 16, 'epochs': 200, 'hidden_dim': 256, 'lr': 0.0001, 'num_gin_layers': 4, 'num_lin_layers': 1, 'random_seed': 42}
Training for parameters: {'batch_size': 16, 'epochs': 200, 'hidden_dim': 256, 'lr': 0.0001, 'num_gin_layers': 4, 'num_lin_layers': 1, 'random_seed': 42}
Epoch 1, Loss: 4.208821776238355, MAE: 1.5758193408901042
Epoch 2, Loss: 2.7339572031389583, MAE: 1.3178116578947414
Epoch 3, Loss: 2.5966356142000717, MAE: 1.2932059144431896
Epoch 4, Loss: 2.5924197616902265, MAE: 1.2858310970393094
Epoch 5, Loss: 2.370825458656658, MAE: 1.2274301910942251
Epoch 6, Loss: 2.32158840786327, MAE: 1.220623631504449
Epoch 7, Loss: 2.3412054563110525, MAE: 1.2211128172549335
Epoch 8, Loss: 2.22361119362441, MAE: 1.1774215947497975
Epoch 9, Loss: 2.2215001052076166, MAE: 1.180897954377261
Epoch 10, Loss: 2.225382817604325, MAE: 1.1861193903467873
Epoch 11, Loss: 2.15165211585435, MAE: 1.1650147527456283
Epoch 12, Loss: 2.106999955935912, MAE: 1.1554165417497808
Epoch 13, Loss: 2.1293517605824905, MAE: 1.1628543761643497
Epoch 14, Loss: 2.038298126919703, MAE: 1.1383697360754013
Epoch 15, Loss: 2.0501685218377546, MAE: 1.1421090480956164
Epoch 16, Loss: 2.0708671163428916, MAE: 1.1446330945600163
Epoch 17, Loss: 1.9632575866850939, MAE: 1.116803857142275
Epoch 18, Loss: 1.9496730961582878, MAE: 1.1197911481965672
Epoch 19, Loss: 2.0300009884617545, MAE: 1.135220449350097
Epoch 20, Loss: 1.9461588526313955, MAE: 1.1110068743879145
Epoch 21, Loss: 1.9296617196364836, MAE: 1.1046698927879333
Epoch 22, Loss: 1.8166863709688186, MAE: 1.0776748538017273
Epoch 23, Loss: 1.9195382624864579, MAE: 1.102990997108546
Epoch 24, Loss: 1.8946091001684016, MAE: 1.1000250298868526
Epoch 25, Loss: 1.8521135490049014, MAE: 1.0802832625129006
Epoch 26, Loss: 1.8139455971392717, MAE: 1.0752713951197537
Epoch 27, Loss: 1.8229957924647764, MAE: 1.0705706496130336
Epoch 28, Loss: 1.8199076760898938, MAE: 1.0747005587274379
Epoch 29, Loss: 1.7458928151564164, MAE: 1.0562850185415962
Epoch 30, Loss: 1.7976702906868673, MAE: 1.0654566519639708
Epoch 31, Loss: 1.731614061106335, MAE: 1.048453049768101
Epoch 32, Loss: 1.7084449571642009, MAE: 1.0371073518287053
Epoch 33, Loss: 1.761238659782843, MAE: 1.0594072759151458
Epoch 34, Loss: 1.7481811206449163, MAE: 1.055274144627831
Epoch 35, Loss: 1.6661389806053855, MAE: 1.0232705953446302
Epoch 36, Loss: 1.6877594365315003, MAE: 1.0358939310366457
Epoch 37, Loss: 1.7400861217217012, MAE: 1.0506140912120991
Epoch 38, Loss: 1.5990778883749788, MAE: 1.004468539086255
Epoch 39, Loss: 1.6047034548087553, MAE: 1.013373979655179
Epoch 40, Loss: 1.6220283296975222, MAE: 1.0046962662176653
Epoch 41, Loss: 1.6024718543345278, MAE: 1.0157780693335967
Epoch 42, Loss: 1.6501778534867546, MAE: 1.015472240610556
Epoch 43, Loss: 1.6617889970541, MAE: 1.029775068434802
Epoch 44, Loss: 1.5827584431930022, MAE: 1.0024564480239695
Epoch 45, Loss: 1.578124596449462, MAE: 1.0093228405172174
Epoch 46, Loss: 1.5487810623916713, MAE: 0.9897000377828424
Epoch 47, Loss: 1.5784479414874857, MAE: 1.0037827088074252
Epoch 48, Loss: 1.5424097296866504, MAE: 0.9920582167126916
Epoch 49, Loss: 1.54260884902694, MAE: 0.9875305900519544
Epoch 50, Loss: 1.496437898955562, MAE: 0.9713872895999388
Epoch 51, Loss: 1.5277361672032963, MAE: 0.9863822275942022
Epoch 52, Loss: 1.5312065667726777, MAE: 0.9818230146711523
Epoch 53, Loss: 1.5002289506522093, MAE: 0.976304771954363
Epoch 54, Loss: 1.4733536603775892, MAE: 0.9642237649722533
Epoch 55, Loss: 1.4899739404970949, MAE: 0.9586296872659164
Epoch 56, Loss: 1.4988103705373677, MAE: 0.9737197721546347
Epoch 57, Loss: 1.4791082806207918, MAE: 0.9666517322713678
Epoch 58, Loss: 1.4667259152639995, MAE: 0.9593855162913149
Epoch 59, Loss: 1.4749767180193554, MAE: 0.9656734443523667
Epoch 60, Loss: 1.393854404173114, MAE: 0.9384719404307279
Epoch 61, Loss: 1.4612312205813147, MAE: 0.9656556370583448
Epoch 62, Loss: 1.429404047673399, MAE: 0.9487072041088884
Epoch 63, Loss: 1.3870735593817451, MAE: 0.9415928203951228
Epoch 64, Loss: 1.4300057552077554, MAE: 0.9572826496579431
Epoch 65, Loss: 1.4629579224369742, MAE: 0.9578286384994333
Epoch 66, Loss: 1.4013460886749354, MAE: 0.9420919255776838
Epoch 67, Loss: 1.389636424725706, MAE: 0.9356881317767229
Epoch 68, Loss: 1.3621866655620662, MAE: 0.9294142097234726
Epoch 69, Loss: 1.389999530125748, MAE: 0.9308485543186015
Epoch 70, Loss: 1.382184005460956, MAE: 0.9313562500205907
Epoch 71, Loss: 1.3665282634171572, MAE: 0.9257751363244924
Epoch 72, Loss: 1.3863648735664107, MAE: 0.9363599839535627
Epoch 73, Loss: 1.3391483029181308, MAE: 0.9162280418656089
Epoch 74, Loss: 1.3778003735975786, MAE: 0.9277592156421054
Epoch 75, Loss: 1.3099135829643769, MAE: 0.9082355344837362
Epoch 76, Loss: 1.329434531114318, MAE: 0.9137279342521321
Epoch 77, Loss: 1.3208429677919908, MAE: 0.9182714620774443
Epoch 78, Loss: 1.2919950982386417, MAE: 0.9015474124388261
Epoch 79, Loss: 1.28128441111608, MAE: 0.8944313485514034
Epoch 80, Loss: 1.276614898443222, MAE: 0.8932680549946699
Epoch 81, Loss: 1.2485925205729225, MAE: 0.8803658754988151
Epoch 82, Loss: 1.2753623589873313, MAE: 0.8941377142613585
Epoch 83, Loss: 1.27073163904927, MAE: 0.8966263177719983
Epoch 84, Loss: 1.2543636838143521, MAE: 0.8854299050840464
Epoch 85, Loss: 1.2339231673966755, MAE: 0.8812699806961146
Epoch 86, Loss: 1.2516035177490927, MAE: 0.8803424323146993
Epoch 87, Loss: 1.2443934429775585, MAE: 0.8776860359040174
Epoch 88, Loss: 1.272890489345247, MAE: 0.8886170190843669
Epoch 89, Loss: 1.2574950063770467, MAE: 0.888671274618669
Epoch 90, Loss: 1.2321229006756436, MAE: 0.8802714739333499
Epoch 91, Loss: 1.2347069545225664, MAE: 0.8832097725434737
Epoch 92, Loss: 1.2505828287113796, MAE: 0.8820143905552951
Epoch 93, Loss: 1.2152294871481981, MAE: 0.8749294039877978
Epoch 94, Loss: 1.1865055575966834, MAE: 0.8615470815788616
Epoch 95, Loss: 1.2365479537031867, MAE: 0.8797439416701144
Epoch 96, Loss: 1.277883593602614, MAE: 0.8939462144266476
Epoch 97, Loss: 1.2758029939098792, MAE: 0.8935204893350601
Epoch 98, Loss: 1.2023608134551482, MAE: 0.8683837037194859
Epoch 99, Loss: 1.2206005716865713, MAE: 0.8779057288711721
Epoch 100, Loss: 1.1744993620298125, MAE: 0.85801508074457
Epoch 101, Loss: 1.2301549564708363, MAE: 0.8783599701794711
Epoch 102, Loss: 1.1637712780724871, MAE: 0.8616911938244646
Epoch 103, Loss: 1.1796348039399494, MAE: 0.8633557028391144
Epoch 104, Loss: 1.191431474550204, MAE: 0.8665166678753766
Epoch 105, Loss: 1.2094851806759834, MAE: 0.865520271117037
Epoch 106, Loss: 1.2065689391710541, MAE: 0.8668187553232366
Epoch 107, Loss: 1.1831653287464923, MAE: 0.8594553749669682
Epoch 108, Loss: 1.1473203087394888, MAE: 0.8476276617158544
Epoch 109, Loss: 1.1388967936689203, MAE: 0.8424842135472731
Epoch 110, Loss: 1.1326542032035913, MAE: 0.8391891254620119
Epoch 111, Loss: 1.1535973437807776, MAE: 0.8528910647739064
Epoch 112, Loss: 1.142385633289814, MAE: 0.8430214104327288
Epoch 113, Loss: 1.1901728708635677, MAE: 0.8686306873505766
Epoch 114, Loss: 1.1247344186360186, MAE: 0.8431407876990058
Epoch 115, Loss: 1.127840409766544, MAE: 0.8447839237072251
Epoch 116, Loss: 1.1398576785217631, MAE: 0.8474235233935443
Epoch 117, Loss: 1.1031917196783152, MAE: 0.8345101917331869
Epoch 118, Loss: 1.1249789278615605, MAE: 0.8390706543218006
Epoch 119, Loss: 1.0905633117664943, MAE: 0.8258613086559555
Epoch 120, Loss: 1.0959000844169746, MAE: 0.8360776513814926
Epoch 121, Loss: 1.0497900301759893, MAE: 0.8149198030883615
Epoch 122, Loss: 1.0926916213198141, MAE: 0.8264461329037492
Epoch 123, Loss: 1.144239428774877, MAE: 0.8483704698356715
Epoch 124, Loss: 1.1205637962980703, MAE: 0.8368432523174719
Epoch 125, Loss: 1.0788873484188861, MAE: 0.8225248595530337
Epoch 126, Loss: 1.080069609528238, MAE: 0.8221052653410218
Epoch 127, Loss: 1.1074041550809688, MAE: 0.8267484705556523
Epoch 128, Loss: 1.096800577234138, MAE: 0.8282849235968156
Epoch 129, Loss: 1.0398741655729034, MAE: 0.8061808214946227
Epoch 130, Loss: 1.106331201575019, MAE: 0.8317369043827056
Epoch 131, Loss: 1.1071396230296655, MAE: 0.8276903198523955
Epoch 132, Loss: 1.0451799068938603, MAE: 0.8127450860359452
Epoch 133, Loss: 1.0808498608795079, MAE: 0.8270796510306272
Epoch 134, Loss: 1.035288659957322, MAE: 0.8037437749179926
Epoch 135, Loss: 1.0602052358063785, MAE: 0.8209697685458444
Epoch 136, Loss: 1.0384597021070394, MAE: 0.7993925315412608
Epoch 137, Loss: 1.0282310754060746, MAE: 0.8071464581923051
Epoch 138, Loss: 1.047491668029265, MAE: 0.805212462219325
Epoch 139, Loss: 1.038227079808712, MAE: 0.8020205522125418
Epoch 140, Loss: 1.01189876686443, MAE: 0.7981557907028631
Epoch 141, Loss: 1.0525483804670248, MAE: 0.8081251340833577
Epoch 142, Loss: 1.0182272325862538, MAE: 0.7983888857743957
Epoch 143, Loss: 1.0277047925374725, MAE: 0.8029581050981175
Epoch 144, Loss: 1.0510178127072074, MAE: 0.8140788086436012
Epoch 145, Loss: 1.0455477595329286, MAE: 0.8015939381989565
Epoch 146, Loss: 0.9929045939987357, MAE: 0.7881385906176134
Epoch 147, Loss: 1.0108808104287494, MAE: 0.7919659527865324
Epoch 148, Loss: 1.0130092818628658, MAE: 0.7981872741471637
Epoch 149, Loss: 1.0294537225907499, MAE: 0.7939498606053266
Epoch 150, Loss: 0.9858130056749691, MAE: 0.7852973175319758
Epoch 151, Loss: 1.0120553409511392, MAE: 0.7968731611967087
Epoch 152, Loss: 1.0073837858709422, MAE: 0.7941751295870001
Epoch 153, Loss: 0.9894141321832484, MAE: 0.7871501917188818
Epoch 154, Loss: 0.9715832309289412, MAE: 0.7771464920856735
Epoch 155, Loss: 0.9850838922641494, MAE: 0.7821214685385878
Epoch 156, Loss: 0.9340718085792932, MAE: 0.7627584525130012
Epoch 157, Loss: 1.0100295484066009, MAE: 0.7962902956388214
Epoch 158, Loss: 0.9828114907172594, MAE: 0.7890344763343985
Epoch 159, Loss: 0.9942546392028982, MAE: 0.7918333938175982
Epoch 160, Loss: 0.9758861574259672, MAE: 0.7810002620924603
Epoch 161, Loss: 0.9660708413882689, MAE: 0.7790341461246664
Epoch 162, Loss: 0.9812157487327402, MAE: 0.7823153298009525
Epoch 163, Loss: 0.9580506131730296, MAE: 0.7770317633043636
Epoch 164, Loss: 0.997072220119563, MAE: 0.7918812237002633
Epoch 165, Loss: 0.9277875232425603, MAE: 0.7533009385520761
Epoch 166, Loss: 0.9516041832891378, MAE: 0.7668333285234191
Epoch 167, Loss: 0.9650869353251024, MAE: 0.775039469789375
Epoch 168, Loss: 0.8960607679052787, MAE: 0.7512520994652402
Epoch 169, Loss: 0.9405710361220619, MAE: 0.7702101444656199
Epoch 170, Loss: 0.9333665266633033, MAE: 0.7677166551351547
Epoch 171, Loss: 0.9570344668897716, MAE: 0.7685867488384247
Epoch 172, Loss: 0.9484734318473123, MAE: 0.7682689445939931
Epoch 173, Loss: 0.9250783065503294, MAE: 0.7593100745569575
Epoch 174, Loss: 0.9178104235367341, MAE: 0.7580733952197162
Epoch 175, Loss: 0.9231031287800182, MAE: 0.7608389580791647
Epoch 176, Loss: 0.9268089314753359, MAE: 0.7545511969111183
Epoch 177, Loss: 0.9835232391953468, MAE: 0.7830907757986676
Epoch 178, Loss: 0.9138349595395001, MAE: 0.7578113020821051
Epoch 179, Loss: 0.9265309501777995, MAE: 0.758536830950867
Epoch 180, Loss: 0.9187118500471115, MAE: 0.7567962016571652
Epoch 181, Loss: 0.8995212122797966, MAE: 0.7474381990053437
Epoch 182, Loss: 0.9127928399226882, MAE: 0.7523936469446529
Epoch 183, Loss: 0.9293049063194881, MAE: 0.7575386968525973
Epoch 184, Loss: 0.9234771431847052, MAE: 0.7553428334268657
Epoch 185, Loss: 0.8890794336118482, MAE: 0.7477615788578987
Epoch 186, Loss: 0.9293982920321551, MAE: 0.7613837346434593
Epoch 187, Loss: 0.9123532003977082, MAE: 0.7506819929588925
Epoch 188, Loss: 0.8824614171277393, MAE: 0.742113083736463
Epoch 189, Loss: 0.8801298633217811, MAE: 0.7414326553994959
Epoch 190, Loss: 0.9042035975239494, MAE: 0.7554797703569586
Epoch 191, Loss: 0.9186809885230931, MAE: 0.7544371166012503
Epoch 192, Loss: 0.9046335129575296, MAE: 0.7505582102320411
Epoch 193, Loss: 0.9096225387670777, MAE: 0.7525184623219751
Epoch 194, Loss: 0.9120550735430284, MAE: 0.7486303199421276
Epoch 195, Loss: 0.8971673727035523, MAE: 0.7490029448812658
Epoch 196, Loss: 0.8575124659321525, MAE: 0.7332960284569047
Epoch 197, Loss: 0.8482568194243041, MAE: 0.7222415353764188
Epoch 198, Loss: 0.8738662123680114, MAE: 0.7380564124746756
Epoch 199, Loss: 0.8513919812034477, MAE: 0.7251431423154744
Epoch 200, Loss: 0.8963635422966697, MAE: 0.7471482203765349
Validation Loss after 200 epochs: 0.8206371935931119
Traceback (most recent call last):
  File "/opt/mamba/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/mamba/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/onyxia/work/aml_project/molprop_prediction/scripts/grid_search_wandb.py", line 182, in <module>
    main()
  File "/home/onyxia/work/aml_project/molprop_prediction/scripts/grid_search_wandb.py", line 174, in main
    best_model, best_params = grid_search(
  File "/home/onyxia/work/aml_project/molprop_prediction/scripts/grid_search_wandb.py", line 143, in grid_search
    f.write(f"{params['hidden_dim']},{params['lr']},{params['batch_size']},{params['epochs']},{params['num_gin_layers']},{params['num_lin_layers']},{average_loss},{avg_mae}\n")
NameError: name 'avg_mae' is not defined