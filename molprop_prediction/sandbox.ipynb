{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preprocess_ter import *\n",
    "from models.GIN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_dataset = \"../dataset/\" + task + \"/\" + dataset + \"/\"\n",
    "radius = 1\n",
    "device = torch.device(\"cpu\")\n",
    "atom_dict = defaultdict(lambda: len(atom_dict))\n",
    "bond_dict = defaultdict(lambda: len(bond_dict))\n",
    "fingerprint_dict = defaultdict(lambda: len(fingerprint_dict))\n",
    "edge_dict = defaultdict(lambda: len(edge_dict))\n",
    "\n",
    "with open(\"../data/raw_data/train_merged.txt\", \"r\") as f:\n",
    "    smiles_property = f.readline().strip().split()\n",
    "    data_original = f.read().strip().split(\"\\n\")\n",
    "\n",
    "\"\"\"Exclude the data contains '.' in its smiles.\"\"\"\n",
    "data_original = [data for data in data_original if \".\" not in data.split()[0]]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for data in data_original:\n",
    "    smiles, property = data.strip().split()\n",
    "\n",
    "    \"\"\"Create each data with the above defined functions.\"\"\"\n",
    "    mol = Chem.AddHs(Chem.MolFromSmiles(smiles))\n",
    "    atoms = create_atoms(mol, atom_dict)\n",
    "    molecular_size = len(atoms)\n",
    "    i_jbond_dict = create_ijbonddict(mol, bond_dict)\n",
    "    fingerprints = extract_fingerprints(\n",
    "        radius, atoms, i_jbond_dict, fingerprint_dict, edge_dict\n",
    "    )\n",
    "    adjacency = Chem.GetAdjacencyMatrix(mol)\n",
    "\n",
    "    \"\"\"Transform the above each data of numpy\n",
    "    to pytorch tensor on a device (i.e., CPU or GPU).\n",
    "    \"\"\"\n",
    "    fingerprints = torch.LongTensor(fingerprints).to(device)\n",
    "    adjacency = torch.FloatTensor(adjacency).to(device)\n",
    "\n",
    "    property = torch.FloatTensor([[float(property)]]).to(device)\n",
    "\n",
    "    dataset.append((fingerprints, adjacency, molecular_size, property))\n",
    "\n",
    "\n",
    "dataset_train = dataset\n",
    "dataset_train, dataset_dev = split_dataset(dataset_train, 0.9)\n",
    "# dataset_test = create_dataset(\"data_test.txt\")\n",
    "\n",
    "# N_fingerprints = len(fingerprint_dict)\n",
    "\n",
    "# dataset_train, dataset_dev, dataset_test, N_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3990"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 67,  68, 107,   3,  12,  11,   5,   8,  57,  26,  11,   5,   5, 108,\n",
       "         109,   5,  73,  74,  31,  53,  31,  19,   5,  45,  46,  14,  60,  35,\n",
       "          24,   1, 107,   3,  13,  34,   0,   0,  20,  20,  20,  21,  22,  21,\n",
       "          22,  22,  22,  22,  22,  20,  20,  20,  20,  20,  20,  20,  20,  21,\n",
       "          20,  20,  20,  20,  20,  20,  20,  20]),\n",
       " tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 64,\n",
       " tensor([[6.0070]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "i = 0\n",
    "for i in range(3900):\n",
    "    fingerprints_tensor = torch.Tensor(dataset[i][0])\n",
    "    adjacency_matrix_tensor = torch.Tensor(dataset[i][1])\n",
    "    molecular_size_tensor = torch.Tensor(dataset[i][2])\n",
    "    target_tensor = dataset[i][3]\n",
    "\n",
    "    sample_data = Data(\n",
    "        x=fingerprints_tensor,\n",
    "        edge_index=adjacency_matrix_tensor,\n",
    "        molecular_size=molecular_size_tensor,\n",
    "        y=target_tensor,\n",
    "    )\n",
    "    dataset.append(sample_data)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:55\u001b[0m, in \u001b[0;36mCollater.collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, OnDiskDataset):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmulti_get(batch))\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:48\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(elem)(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader found invalid type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(elem)(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader found invalid type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:34\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(\n\u001b[1;32m     29\u001b[0m         batch,\n\u001b[1;32m     30\u001b[0m         follow_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch,\n\u001b[1;32m     31\u001b[0m         exclude_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys,\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, TensorFrame):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_frame\u001b[38;5;241m.\u001b[39mcat(batch, along\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got tuple"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torchsummary import summary\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'stores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m total_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Nouvelle variable pour stocker la somme des MAE\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:55\u001b[0m, in \u001b[0;36mCollater.collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, OnDiskDataset):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmulti_get(batch))\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:28\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/data/batch.py:93\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     83\u001b[0m                    follow_batch: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     84\u001b[0m                    exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)\n\u001b[1;32m    103\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aml_project-HWNn8X9G/lib/python3.11/site-packages/torch_geometric/data/collate.py:54\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     52\u001b[0m key_to_stores \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_list:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstores\u001b[49m:\n\u001b[1;32m     55\u001b[0m         key_to_stores[store\u001b[38;5;241m.\u001b[39m_key]\u001b[38;5;241m.\u001b[39mappend(store)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# With this, we iterate over each list of storage objects and recursively\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# collate all its attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#   elements as attributes that got incremented need to be decremented\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#   while separating to obtain original values.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'stores'"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "input_dim = 1\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "model = GIN(hidden_dim, input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "mae = nn.L1Loss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_mae = 0  # Nouvelle variable pour stocker la somme des MAE\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x, edge_index, batch_data = batch.x, batch.edge_index, batch.batch\n",
    "        output = model(x, edge_index, batch_data)\n",
    "        loss = criterion(output, batch.y.view(-1, 1))\n",
    "        mae_value = mae(output, batch.y.view(-1, 1))  # Calcul de la MAE\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_mae += mae_value.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    average_mae = total_mae / len(train_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {average_loss}, MAE: {average_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class MolecularGraphData(Data):\n",
    "    def __init__(self, fingerprints, adjacency_matrix, molecular_size, target):\n",
    "        super(MolecularGraphData, self).__init__()\n",
    "        self.x = fingerprints  # Node features (fingerprints)\n",
    "        self.edge_index = adjacency_matrix  # Edge connectivity\n",
    "        self.molecular_size = molecular_size  # Size of the molecular graph\n",
    "        self.y = target  # Target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def onehot_encode(x, features:list):\n",
    "    \"\"\"\n",
    "    Maps input elements x not in features to the last element\n",
    "    \"\"\"\n",
    "    if x not in features: x = features[-1]\n",
    "    binary_encoding = [int(bool_val) for bool_val in list(\n",
    "       map(lambda s: x == s, features))]\n",
    "    return binary_encoding\n",
    "  \n",
    "class onehot_encodings:\n",
    "  ''' encoding class for one hot features'''\n",
    "  def __init__(self, atom_info_func, features):\n",
    "    self.atom_info_func = atom_info_func\n",
    "    self.features = features\n",
    "  \n",
    "  #@property\n",
    "  def onehot_encodings(self, atom):\n",
    "    return onehot_encode(self.atom_info_func(atom), self.features)\n",
    "  \n",
    "  def __len__(self): return len(self.features)\n",
    "\n",
    "def json_to_list(json_file):\n",
    "  with open(json_file, 'r') as f:\n",
    "    input_data = list(json.load(f).values())\n",
    "  print(f\"Loaded json from: {json_file}\")\n",
    "  return input_data\n",
    "\n",
    "def list_to_json(json_file, input_list):\n",
    "  with open(json_file, 'w') as f:\n",
    "    json.dump(input_list, f)\n",
    "  print(f\"Output json saved to: {json_file}\")\n",
    "  \n",
    "from rdkit import Chem\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "\n",
    "class FeaturesArgs:\n",
    "    # encodings information\n",
    "    available_atoms = [\n",
    "        \"C\",\n",
    "        \"N\",\n",
    "        \"O\",\n",
    "        \"S\",\n",
    "        \"F\",\n",
    "        \"Si\",\n",
    "        \"P\",\n",
    "        \"Cl\",\n",
    "        \"Br\",\n",
    "        \"Mg\",\n",
    "        \"Na\",\n",
    "        \"Ca\",\n",
    "        \"Fe\",\n",
    "        \"As\",\n",
    "        \"Al\",\n",
    "        \"I\",\n",
    "        \"B\",\n",
    "        \"V\",\n",
    "        \"K\",\n",
    "        \"Tl\",\n",
    "        \"Yb\",\n",
    "        \"Sb\",\n",
    "        \"Sn\",\n",
    "        \"Ag\",\n",
    "        \"Pd\",\n",
    "        \"Co\",\n",
    "        \"Se\",\n",
    "        \"Ti\",\n",
    "        \"Zn\",\n",
    "        \"Li\",\n",
    "        \"Ge\",\n",
    "        \"Cu\",\n",
    "        \"Au\",\n",
    "        \"Ni\",\n",
    "        \"Cd\",\n",
    "        \"In\",\n",
    "        \"Mn\",\n",
    "        \"Zr\",\n",
    "        \"Cr\",\n",
    "        \"Pt\",\n",
    "        \"Hg\",\n",
    "        \"Pb\",\n",
    "        \"Unknown\",\n",
    "    ]\n",
    "    chirality = [\n",
    "        \"CHI_UNSPECIFIED\",\n",
    "        \"CHI_TETRAHEDRAL_CW\",\n",
    "        \"CHI_TETRAHEDRAL_CCW\",\n",
    "        \"CHI_OTHER\",\n",
    "    ]\n",
    "    num_hydrogens = [0, 1, 2, 3, 4, \"MoreThanFour\"]\n",
    "    n_heavy_atoms = num_hydrogens\n",
    "    formal_charges = [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"]\n",
    "    hybridisation_type = [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"]\n",
    "    # Atoms\n",
    "    # atom encodings\n",
    "    atom_encoding_lambdas = {\n",
    "        \"available_atoms\": onehot_encodings(\n",
    "            lambda atom: str(atom.GetSymbol()), available_atoms\n",
    "        ),\n",
    "        \"chirality_type_enc\": onehot_encodings(\n",
    "            lambda atom: str(atom.GetChiralTag()), chirality\n",
    "        ),\n",
    "        \"hydrogens_implicit\": onehot_encodings(\n",
    "            lambda atom: int(atom.GetTotalNumHs()), num_hydrogens\n",
    "        ),\n",
    "        \"n_heavy_atoms\": onehot_encodings(\n",
    "            lambda atom: int(atom.GetDegree()), n_heavy_atoms\n",
    "        ),\n",
    "        \"formal_charge\": onehot_encodings(\n",
    "            lambda atom: int(atom.GetFormalCharge()), formal_charges\n",
    "        ),\n",
    "        \"hybridisation_type\": onehot_encodings(\n",
    "            lambda atom: str(atom.GetHybridization()), hybridisation_type\n",
    "        ),\n",
    "    }\n",
    "    # atom info\n",
    "    atom_info_lambdas = {\n",
    "        \"is_in_a_ring_enc\": lambda atom: [int(atom.IsInRing())],\n",
    "        \"is_aromatic_enc\": lambda atom: [int(atom.GetIsAromatic())],\n",
    "        \"atomic_mass_scaled\": lambda atom: [float((atom.GetMass() - 10.812) / 116.092)],\n",
    "        \"vdw_radius_scaled\": lambda atom: [\n",
    "            float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5) / 0.6)\n",
    "        ],\n",
    "        \"covalent_radius_scaled\": lambda atom: [\n",
    "            float(\n",
    "                (Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)\n",
    "                / 0.76\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    "    # compute node feature length\n",
    "    n_node_features = sum(map(len, atom_encoding_lambdas.values()))\n",
    "    n_node_features += len(atom_info_lambdas)\n",
    "\n",
    "    # Bonds encoding info\n",
    "    bond_types = [\n",
    "        Chem.rdchem.BondType.SINGLE,\n",
    "        Chem.rdchem.BondType.DOUBLE,\n",
    "        Chem.rdchem.BondType.TRIPLE,\n",
    "        Chem.rdchem.BondType.AROMATIC,\n",
    "    ]\n",
    "    stereo_types = [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"]\n",
    "    # bond encodings\n",
    "    bond_encoding_lambdas = {\n",
    "        \"bond_types\": onehot_encodings(lambda bond: bond.GetBondType(), bond_types),\n",
    "        \"stereo_types\": onehot_encodings(\n",
    "            lambda bond: str(bond.GetStereo()), stereo_types\n",
    "        ),\n",
    "    }\n",
    "    # bond quantity\n",
    "    bond_info_lambas = {\n",
    "        \"bond_is_conj_enc\": lambda bond: [int(bond.GetIsConjugated())],\n",
    "        \"bond_is_in_ring_enc\": lambda bond: [int(bond.IsInRing())],\n",
    "    }\n",
    "    n_edge_features = sum(map(len, bond_encoding_lambdas.values()))\n",
    "    n_edge_features += len(bond_info_lambas)\n",
    "    #\n",
    "    n_features = n_edge_features + n_node_features\n",
    "    # Molecule\n",
    "    # lambda mol: GraphDescriptors.BalabanJ(mol)\n",
    "\n",
    "\n",
    "class ModelArgs:\n",
    "    available_models = [\"GIN\"]\n",
    "    model = \"GIN\"\n",
    "\n",
    "\n",
    "class TrainArgs:\n",
    "    batch_size = 2**5\n",
    "    lr = 5e-3\n",
    "    weight_decay = 5e-4\n",
    "    epochs = 20\n",
    "    name = \"default-GIN\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_save_pt = Path(f\"./model/{name}.pth\")\n",
    "\n",
    "\n",
    "class InferArgs:\n",
    "    batch_size = 1\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    name = \"default-GIN\"\n",
    "    output_path = Path(\"./output\")\n",
    "    model_save_pt = Path(f\"./model/{name}.pth\")\n",
    "\n",
    "\n",
    "class DataArgs:\n",
    "    data_source = Path(\"data/kinase_JAK.csv\")\n",
    "    num_workers = 4\n",
    "    device = TrainArgs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from models.GIN import GIN\n",
    "from scripts.preprocess import MolDataset\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "\n",
    "def load_params(config_path):\n",
    "    with open(config_path, \"r\") as config_file:\n",
    "        params = json.load(config_file)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\n",
    "    \"/Users/emanieluu/Documents/ENSAE/3A/Advanced Machine Learning/aml_project/data/raw_data/train_merged_data.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "train_dataset = MolDataset(train_data)\n",
    "test_dataset = MolDataset(test_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import GraphDescriptors\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# from .util import onehot_encodings\n",
    "\n",
    "def get_atom_features(\n",
    "    atom,\n",
    "    available_atoms: list = FeaturesArgs.available_atoms,\n",
    "    atom_encode_lambdas: dict = FeaturesArgs.atom_encoding_lambdas,\n",
    "    atom_info_lambdas: dict = FeaturesArgs.atom_info_lambdas,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "    if \"hydrogens_implicit\" in atom_encode_lambdas:\n",
    "        available_atoms = [\"H\"] + available_atoms\n",
    "    atom_feature_vector = []\n",
    "    # compute atom features\n",
    "    for name, atom_encoding in atom_encode_lambdas.items():\n",
    "        encoding = atom_encoding.onehot_encodings(atom)\n",
    "        atom_feature_vector += encoding\n",
    "        if debug:\n",
    "            print(f\"atom encoding length ({name}): {len(encoding)}\")\n",
    "        # boolean features\n",
    "    for name, info_func in atom_info_lambdas.items():\n",
    "        atom_feature_vector += info_func(atom)\n",
    "        if debug:\n",
    "            print(f\"atom info ({name}): {info_func(atom)}\")\n",
    "    if debug:\n",
    "        print(f\"full atom feature:{len(atom_feature_vector)}\")\n",
    "    return torch.Tensor(atom_feature_vector)\n",
    "\n",
    "\n",
    "def get_bond_features(\n",
    "    bond,\n",
    "    bond_encoding_lambdas: dict = FeaturesArgs.bond_encoding_lambdas,\n",
    "    bond_info_lambdas: dict = FeaturesArgs.bond_info_lambas,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "    bond_feature_vector = []\n",
    "    # compute bond features\n",
    "    for name, bond_encoding in bond_encoding_lambdas.items():\n",
    "        encoding = bond_encoding.onehot_encodings(bond)\n",
    "        bond_feature_vector += encoding\n",
    "        if debug:\n",
    "            print(f\"bond encoding length ({name}): {len(bond_feature_vector)}\")\n",
    "        # boolean features\n",
    "    for name, info_func in bond_info_lambdas.items():\n",
    "        bond_feature_vector += info_func(bond)\n",
    "        if debug:\n",
    "            print(f\"bond info ({name}): {info_func(bond)}\")\n",
    "        return torch.Tensor(bond_feature_vector)\n",
    "\n",
    "\n",
    "def smile_to_data(smiles, y_val):\n",
    "    \"\"\"smile to pyg Data components\"\"\"\n",
    "    # convert SMILES to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # get feature dimensions\n",
    "    n_nodes = mol.GetNumAtoms()\n",
    "    n_edges = 2 * mol.GetNumBonds()\n",
    "\n",
    "    # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "    for n, atom in enumerate(mol.GetAtoms()):\n",
    "        atom_features = get_atom_features(atom)\n",
    "        if n == 0:\n",
    "            X = torch.zeros((n_nodes, len(atom_features)), dtype=torch.float)\n",
    "        X[atom.GetIdx(), :] = atom_features\n",
    "\n",
    "    # construct edge index array E of shape (2, n_edges)\n",
    "    E_ij = torch.stack(\n",
    "        list(\n",
    "            map(\n",
    "                lambda arr: torch.Tensor(arr).to(torch.long),\n",
    "                np.nonzero(GetAdjacencyMatrix(mol)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "    EF = torch.stack(\n",
    "        [\n",
    "            get_bond_features(mol.GetBondBetweenAtoms(i.item(), j.item()))\n",
    "            for i, j in zip(E_ij[0], E_ij[1])\n",
    "        ]\n",
    "    )\n",
    "    # construct label tensor\n",
    "    y_tensor = torch.tensor(np.array([y_val]), dtype=torch.float)\n",
    "    return X, E_ij, EF, y_tensor\n",
    "\n",
    "\n",
    "def graph_datalist_from_smiles_and_labels(x_smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      x_smiles [list]: SMILES strings\n",
    "      y [list]: numerial labels for the SMILES strings\n",
    "    Outputs:\n",
    "      data_list [list]: torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
    "\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for smiles, y_val in zip(x_smiles, y):\n",
    "        X, E, EF, y_tensor = smile_to_data(smiles, y_val)\n",
    "        # construct Pytorch Geometric data object list\n",
    "        data_list.append(Data(x=X, edge_index=E, edge_attr=EF, y=y_tensor))\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def Molecule_pKa_dataloader(\n",
    "    df,\n",
    "    batch_size,\n",
    "    num_workers: int = 1,\n",
    "    shuffle=False,\n",
    "    device=\"cpu\",\n",
    "    processed_dataset_path=\"./data\",\n",
    "):\n",
    "    smile_col, label_col = \"SMILES\", \"measurement_value\"\n",
    "    x_smiles, y = df[smile_col].to_numpy(), df[label_col].to_numpy()\n",
    "\n",
    "    # create list of molecular graph objects from list of SMILES x_smiles and list of labels y\n",
    "    data_list = graph_datalist_from_smiles_and_labels(x_smiles, y)\n",
    "    dataset = Molecule_pKa(processed_dataset_path, data_list)\n",
    "    # create dataloader for training\n",
    "    dataloader = DataLoader(\n",
    "        dataset=data_list,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)),\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smile_to_data(smiles, y_val):\n",
    "    \"\"\"smile to pyg Data components\"\"\"\n",
    "    # convert SMILES to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # get feature dimensions\n",
    "    n_nodes = mol.GetNumAtoms()\n",
    "    n_edges = 2 * mol.GetNumBonds()\n",
    "\n",
    "    # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "    for n, atom in enumerate(mol.GetAtoms()):\n",
    "        atom_features = get_atom_features(atom)\n",
    "        if n == 0:\n",
    "            X = torch.zeros((n_nodes, len(atom_features)), dtype=torch.float)\n",
    "        X[atom.GetIdx(), :] = atom_features\n",
    "\n",
    "    # construct edge index array E of shape (2, n_edges)\n",
    "    E_ij = torch.stack(\n",
    "        list(\n",
    "            map(\n",
    "                lambda arr: torch.Tensor(arr).to(torch.long),\n",
    "                np.nonzero(GetAdjacencyMatrix(mol)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "    EF = torch.stack(\n",
    "        [\n",
    "            get_bond_features(mol.GetBondBetweenAtoms(i.item(), j.item()))\n",
    "            for i, j in zip(E_ij[0], E_ij[1])\n",
    "        ]\n",
    "    )\n",
    "    # construct label tensor\n",
    "    y_tensor = torch.tensor(np.array([y_val]), dtype=torch.float)\n",
    "    return X, E_ij, EF, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.loc[0].smiles\n",
    "y = train_data.loc[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, E_ij, EF, y_tensor = smile_to_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = graph_datalist_from_smiles_and_labels(train_data[\"smiles\"], train_data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[28, 79], edge_index=[2, 62], edge_attr=[62, 9], y=[1])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project-HWNn8X9G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
